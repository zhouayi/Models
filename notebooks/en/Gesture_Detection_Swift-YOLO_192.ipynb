{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhouayi/Models/blob/main/notebooks/en/Gesture_Detection_Swift-YOLO_192.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-B67pF11FkJ"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <h1>Welcom to SSCMA for Google Colab Training Example 🔥 </h1>\n",
        "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://sensecraftma.seeed.cc/images/SSCMA-Hero.png\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI52Au7i1FkN"
      },
      "source": [
        "# Gesture Detection - Swift-YOLO\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/Gesture_Detection_Swift-YOLO_192.ipynb)\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/yolov5/swift_yolo_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** [Gesture](https://universe.roboflow.com/rsp/paper-aaj0p/dataset/33)\n",
        "\n",
        "**Class:** `paper`, `rock`, `scissors`\n",
        "\n",
        "![Gesture Detection](https://files.seeedstudio.com/sscma/static/detection_gesture.png)\n",
        "\n",
        "The model is a Swift-YOLO model trained on the gesture detection dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahwolvgY1FkN"
      },
      "source": [
        "## ⚙️Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rlBunJnp1FkO",
        "outputId": "81cb4cbd-11b0-4723-da8e-386df9ed71d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ModelAssistant'...\n",
            "remote: Enumerating objects: 7477, done.\u001b[K\n",
            "remote: Counting objects: 100% (2228/2228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (881/881), done.\u001b[K\n",
            "remote: Total 7477 (delta 1522), reused 1833 (delta 1332), pack-reused 5249\u001b[K\n",
            "Receiving objects: 100% (7477/7477), 18.42 MiB | 26.05 MiB/s, done.\n",
            "Resolving deltas: 100% (4346/4346), done.\n",
            "/content/ModelAssistant\n",
            "Checking if CUDA available... \u001b[032mOK\u001b[m\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=62ea827b1874aaf4f4c18f87d78bcd0aab9b41f5819f6b4136ecb5aeefea1949\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu121\n",
            "    Uninstalling torchaudio-2.1.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
            "Installing base deps... Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from -r requirements/export.txt (line 2))\n",
            "  Downloading https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 2)) (1.3.1)\n",
            "Collecting cbor (from -r requirements/base.txt (line 5))\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 6)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 9)) (4.8.0.76)\n",
            "Collecting openmim>=0.3.7 (from -r requirements/base.txt (line 12))\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 13)) (23.2)\n",
            "Collecting pandas>=2.0.0 (from -r requirements/base.txt (line 14))\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 15)) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 16)) (6.0.1)\n",
            "Collecting scikit-image>=0.20.0 (from -r requirements/base.txt (line 17))\n",
            "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 18)) (1.2.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 21)) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 24)) (2.15.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/base.txt (line 25)) (4.66.1)\n",
            "Collecting pyvww (from -r requirements/base.txt (line 28))\n",
            "  Downloading pyvww-0.1.1-py3-none-any.whl (8.9 kB)\n",
            "Collecting libusb1>=3.0.0 (from -r requirements/inference.txt (line 1))\n",
            "  Downloading libusb1-3.1.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ncnn>=1.0.20230517 (from -r requirements/inference.txt (line 2))\n",
            "  Downloading ncnn-1.0.20231027-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx>=1.14.0 (from -r requirements/inference.txt (line 3))\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxmltools>=1.11.2 (from -r requirements/inference.txt (line 4))\n",
            "  Downloading onnxmltools-1.12.0-py2.py3-none-any.whl (329 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.15.1 (from -r requirements/inference.txt (line 5))\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxsim>=0.4.33 (from -r requirements/inference.txt (line 6))\n",
            "  Downloading onnxsim-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=4.23.3 (from -r requirements/inference.txt (line 7))\n",
            "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements/inference.txt (line 8)) (2.15.0)\n",
            "Collecting pnnx (from -r requirements/export.txt (line 5))\n",
            "  Downloading pnnx-20231220-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black>=23.3.0 (from -r requirements/tests.txt (line 1))\n",
            "  Downloading black-23.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.12.0 (from -r requirements/tests.txt (line 2))\n",
            "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pre-commit>=3.3.3 (from -r requirements/tests.txt (line 3))\n",
            "  Downloading pre_commit-3.6.0-py2.py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.0/204.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruff>=0.0.275 (from -r requirements/tests.txt (line 4))\n",
            "  Downloading ruff-0.1.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.3.0->-r requirements/base.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.3.0->-r requirements/base.txt (line 2)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.3.0->-r requirements/base.txt (line 2)) (4.8.1.78)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 12)) (8.1.7)\n",
            "Collecting colorama (from openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 12)) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 12)) (13.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 14)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 14)) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas>=2.0.0->-r requirements/base.txt (line 14))\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 17)) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 17)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 17)) (2023.12.9)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 17)) (0.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 18)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 18)) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->-r requirements/base.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (3.5.1)\n",
            "Collecting protobuf>=4.23.3 (from -r requirements/inference.txt (line 7))\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (3.0.1)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 28)) (2.0.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyvww->-r requirements/base.txt (line 28)) (0.15.1)\n",
            "Collecting portalocker (from ncnn>=1.0.20230517->-r requirements/inference.txt (line 2))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 5))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 5)) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (2.15.0)\n",
            "Collecting ruamel.yaml>=0.16.12 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting igraph>=0.9 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading igraph-0.11.3-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pnnx->-r requirements/export.txt (line 5)) (2.0.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (4.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (2.0.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading identify-2.5.33-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading virtualenv-20.25.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 8)) (0.42.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements/base.txt (line 21)) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (1.3.1)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 12)) (2023.11.17)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (2.1.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.1->-r requirements/inference.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set (from model-index->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openxlab (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.9/298.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->pyvww->-r requirements/base.txt (line 28)) (3.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 12)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->-r requirements/inference.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pnnx->-r requirements/export.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pnnx->-r requirements/export.txt (line 5)) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pnnx->-r requirements/export.txt (line 5)) (17.0.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim>=0.3.7->-r requirements/base.txt (line 12)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 28)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 28)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 28)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 28)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww->-r requirements/base.txt (line 28)) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->-r requirements/base.txt (line 24)) (3.2.2)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard>=2.12.3->-r requirements/base.txt (line 24))\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.65.0 (from -r requirements/base.txt (line 25))\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 12)) (41.0.7)\n",
            "Building wheels for collected packages: cbor, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53435 sha256=d00393610218b3a2b677904c19d960f466baf7d5f55132cc81d311576cf60a8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=026a325fa13e1ce68ac46c02055df3f7aa65ba56ace823036ebdc04dc0be9a8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=bc5690116a0f671f4367c4ba52acaecca0b3c268189edfffff4b835899679813\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31410 sha256=31ffd15be39faf6f7c45f67b1617a7315e11d226525ac49d2b2a505fbe28bf12\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built cbor oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: texttable, libusb1, distlib, crcmod, cbor, virtualenv, urllib3, tzdata, tqdm, setuptools, ruff, ruamel.yaml.clib, pycryptodome, protobuf, portalocker, pathspec, ordered-set, mypy-extensions, jmespath, isort, igraph, identify, humanfriendly, colorama, cfgv, scikit-image, ruamel.yaml, rich, requests, pandas, onnx, nodeenv, model-index, coloredlogs, black, TinyNeuralNetwork, pre-commit, onnxsim, onnxruntime, onnxmltools, ncnn, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim, pyvww, pnnx\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.17.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.1.4 which is incompatible.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
            "yfinance 0.2.33 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TinyNeuralNetwork-0.1.1 aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 black-23.12.1 cbor-1.0.0 cfgv-3.4.0 colorama-0.4.6 coloredlogs-15.0.1 crcmod-1.7 distlib-0.3.8 humanfriendly-10.0 identify-2.5.33 igraph-0.11.3 isort-5.13.2 jmespath-0.10.0 libusb1-3.1.0 model-index-0.1.11 mypy-extensions-1.0.0 ncnn-1.0.20231027 nodeenv-1.8.0 onnx-1.15.0 onnxmltools-1.12.0 onnxruntime-1.16.3 onnxsim-0.4.35 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.32 ordered-set-4.1.0 oss2-2.17.0 pandas-2.1.4 pathspec-0.12.1 pnnx-20231220 portalocker-2.8.2 pre-commit-3.6.0 protobuf-4.23.4 pycryptodome-3.19.0 pyvww-0.1.1 requests-2.28.2 rich-13.4.2 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 ruff-0.1.9 scikit-image-0.22.0 setuptools-60.2.0 texttable-1.7.0 tqdm-4.65.2 tzdata-2023.3 urllib3-1.26.18 virtualenv-20.25.0\n",
            "Installing OpenMIM deps... \n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmyolo@ https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl (from -r requirements/mmlab.txt (line 8))\n",
            "  Downloading https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.9/385.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmcls>=1.0.0.rc6 (from -r requirements/mmlab.txt (line 2))\n",
            "  Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl (906 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.1/906.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmcv>=2.0.0 (from -r requirements/mmlab.txt (line 3))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmdet<3.1.0,>=3.0.0 (from -r requirements/mmlab.txt (line 4))\n",
            "  Downloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmengine>=0.8.2 (from -r requirements/mmlab.txt (line 5))\n",
            "  Downloading mmengine-0.10.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.3/450.3 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmpose>=1.0.0 (from -r requirements/mmlab.txt (line 6))\n",
            "  Downloading mmpose-1.2.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.7.1)\n",
            "Collecting modelindex (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (13.4.2)\n",
            "Collecting addict (from mmcv>=2.0.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (6.0.1)\n",
            "Collecting yapf (from mmcv>=2.0.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.16.0)\n",
            "Collecting terminaltables (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4))\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Collecting mmcv>=2.0.0 (from -r requirements/mmlab.txt (line 3))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (74.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->-r requirements/mmlab.txt (line 5)) (2.4.0)\n",
            "Collecting chumpy (from mmpose>=1.0.0->-r requirements/mmlab.txt (line 6))\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting json-tricks (from mmpose>=1.0.0->-r requirements/mmlab.txt (line 6))\n",
            "  Downloading json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\n",
            "Collecting munkres (from mmpose>=1.0.0->-r requirements/mmlab.txt (line 6))\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (0.15.1)\n",
            "Collecting xtcocotools>=1.12 (from mmpose>=1.0.0->-r requirements/mmlab.txt (line 6))\n",
            "  Downloading xtcocotools-1.14.3-cp310-cp310-manylinux1_x86_64.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmyolo@ https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl->-r requirements/mmlab.txt (line 8)) (3.9.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (60.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.11)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->mmyolo@ https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl->-r requirements/mmlab.txt (line 8)) (0.2.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (2.28.2)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (17.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (4.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0->-r requirements/mmlab.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.5.1)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchvision->mmpose>=1.0.0->-r requirements/mmlab.txt (line 6)) (1.3.0)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58281 sha256=bc17af7e9c8090edc02d3e09d9086a5331cd1faa3876e0e558f7344f244a635b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/c1/ef/29ba7be03653a29ef6f2c3e1956d6c4d8877f2b243af411db1\n",
            "Successfully built chumpy\n",
            "Installing collected packages: munkres, json-tricks, addict, terminaltables, yapf, modelindex, chumpy, xtcocotools, mmengine, mmcv, mmdet, mmcls, mmyolo, mmpose\n",
            "Successfully installed addict-2.4.0 chumpy-0.70 json-tricks-3.17.3 mmcls-1.0.0rc6 mmcv-2.0.1 mmdet-3.0.0 mmengine-0.10.1 mmpose-1.2.0 mmyolo-0.5.0 modelindex-0.0.2 munkres-1.1.4 terminaltables-3.1.10 xtcocotools-1.14.3 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Obtaining file:///content/ModelAssistant\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from sscma==2.0.0rc3)\n",
            "  Using cached https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "Collecting mmyolo@ https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl (from sscma==2.0.0rc3)\n",
            "  Using cached https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl (385 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.15.1)\n",
            "Requirement already satisfied: albumentations>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: cbor in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.7.0.72 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.8.0.76)\n",
            "Requirement already satisfied: openmim>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.3.9)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (23.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (6.0.1)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.22.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.2.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.15.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.65.2)\n",
            "Requirement already satisfied: pyvww in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.1.1)\n",
            "Requirement already satisfied: libusb1>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.1.0)\n",
            "Requirement already satisfied: ncnn>=1.0.20230517 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.20231027)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.15.0)\n",
            "Requirement already satisfied: onnxmltools>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.12.0)\n",
            "Requirement already satisfied: onnxruntime>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.16.3)\n",
            "Requirement already satisfied: onnxsim>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.4.35)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (4.23.4)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: pnnx in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (20231220)\n",
            "Requirement already satisfied: black>=23.3.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (23.12.1)\n",
            "Requirement already satisfied: isort>=5.12.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (5.13.2)\n",
            "Requirement already satisfied: pre-commit>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.6.0)\n",
            "Requirement already satisfied: ruff>=0.0.275 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.1.9)\n",
            "Requirement already satisfied: mmcls>=1.0.0.rc6 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.0.0rc6)\n",
            "Requirement already satisfied: mmcv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: mmdet<3.1.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: mmengine>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (0.10.1)\n",
            "Requirement already satisfied: mmpose>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from sscma==2.0.0rc3) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.3.0->sscma==2.0.0rc3) (1.11.4)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.3.0->sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.3.0->sscma==2.0.0rc3) (4.8.1.78)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.7.1)\n",
            "Requirement already satisfied: modelindex in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (13.4.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0->sscma==2.0.0rc3) (0.40.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.7)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (3.1.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.8.2->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: chumpy in /usr/local/lib/python3.10/dist-packages (from mmpose>=1.0.0->sscma==2.0.0rc3) (0.70)\n",
            "Requirement already satisfied: json-tricks in /usr/local/lib/python3.10/dist-packages (from mmpose>=1.0.0->sscma==2.0.0rc3) (3.17.3)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.10/dist-packages (from mmpose>=1.0.0->sscma==2.0.0rc3) (1.1.4)\n",
            "Requirement already satisfied: xtcocotools>=1.12 in /usr/local/lib/python3.10/dist-packages (from mmpose>=1.0.0->sscma==2.0.0rc3) (1.14.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.28.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.8.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.12)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.0.10)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (23.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2023.3)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (2.5.33)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (20.25.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2023.12.9)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (0.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (60.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.34.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (3.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2.0.0->sscma==2.0.0rc3) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->sscma==2.0.0rc3) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->sscma==2.0.0rc3) (17.0.6)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmyolo@ https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl->sscma==2.0.0rc3) (3.9.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.12 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.18.5)\n",
            "Requirement already satisfied: igraph>=0.9 in /usr/local/lib/python3.10/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.11.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->sscma==2.0.0rc3) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (2023.11.17)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.2.8)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->sscma==2.0.0rc3) (0.3.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->sscma==2.0.0rc3) (2.1.3)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose>=1.0.0->sscma==2.0.0rc3) (3.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.1.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.15.1->sscma==2.0.0rc3) (10.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim>=0.3.7->sscma==2.0.0rc3) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (3.19.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.0.32)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->mmyolo@ https://files.seeedstudio.com/sscma/library/mmyolo-0.5.0-py3-none-any.whl->sscma==2.0.0rc3) (0.2.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0->sscma==2.0.0rc3) (7.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0->sscma==2.0.0rc3) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.12.3->sscma==2.0.0rc3) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.12.3->sscma==2.0.0rc3) (3.2.2)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.17.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.2)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.14.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (41.0.7)\n",
            "Building wheels for collected packages: sscma\n",
            "  Building editable for sscma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sscma: filename=sscma-2.0.0rc3-0.editable-py3-none-any.whl size=6070 sha256=a0176f52fc8bb94621a056d4bc08ef9c06e26cf0aecf0f4c6310d7c45d2ead40\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7kvtvlpa/wheels/90/1c/ba/0dcfb496beef1b933cf590042cc252e1a365a514ee48989a82\n",
            "Successfully built sscma\n",
            "Installing collected packages: sscma\n",
            "Successfully installed sscma-2.0.0rc3\n",
            "Finished setup... \u001b[032mOK\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git   #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7SJkc391FkP"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "10qY5bfn1FkP",
        "outputId": "c083d994-ca49-4514-aec1-21b14d7e93ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-25 07:25:41--  https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth\n",
            "Resolving files.seeedstudio.com (files.seeedstudio.com)... 13.249.85.116, 13.249.85.5, 13.249.85.41, ...\n",
            "Connecting to files.seeedstudio.com (files.seeedstudio.com)|13.249.85.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12822891 (12M) [application/octet-stream]\n",
            "Saving to: ‘Gesture_Detection_Swift-YOLO_192/pretrain.pth’\n",
            "\n",
            "Gesture_Detection_S 100%[===================>]  12.23M  28.2MB/s    in 0.4s    \n",
            "\n",
            "2023-12-25 07:25:41 (28.2 MB/s) - ‘Gesture_Detection_Swift-YOLO_192/pretrain.pth’ saved [12822891/12822891]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p Gesture_Detection_Swift-YOLO_192\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth -O Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e1kgZUv1FkQ"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2yUSJFwV1FkR",
        "outputId": "c6978525-40f0-45db-c295-11aeec28bcda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-25 07:25:46--  https://universe.roboflow.com/ds/xaMM3ZTeWy?key=5bznPZyI0t\n",
            "Resolving universe.roboflow.com (universe.roboflow.com)... 151.101.1.195, 151.101.65.195\n",
            "Connecting to universe.roboflow.com (universe.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-exports/6wojE7svfZ8Lhy4WFzQ3/4QAjh8ko3NJg608ogyfz/33/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20231225%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20231225T072546Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=73049bb57cfdbe949494a9af727b6ecbe853ff766a631334249e6fb0bf95f26662ee543c443362f0dac9c861be567ed37c5b769c25525ebbdb6bb31aab04f8d07bec3c09121bd5c8298c913747f7ad968d4303a7497eff071e66a3dc971e1d3240cf6a2451f1f9a9b6ea00202eb541fbe0e2f9754e1802370ed1b7cd9d35d6d9b57fc80833fd38a27b7eae4d55b54392aacd4276c945b31eb0fef44c1f3e66a20c16c7ed054a86fbd4183825758c5245bcb65b42be96d981f7b31532e8a5f492aeeef53f00df4208480f4da2879f7bdb18e9ecc6fb7d9637ab90392baf2b951e2af63950008d6fba02fea6eb00e3101eff9295447b785e0d1fe48aeff0fff7bd [following]\n",
            "--2023-12-25 07:25:46--  https://storage.googleapis.com/roboflow-platform-exports/6wojE7svfZ8Lhy4WFzQ3/4QAjh8ko3NJg608ogyfz/33/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20231225%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20231225T072546Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=73049bb57cfdbe949494a9af727b6ecbe853ff766a631334249e6fb0bf95f26662ee543c443362f0dac9c861be567ed37c5b769c25525ebbdb6bb31aab04f8d07bec3c09121bd5c8298c913747f7ad968d4303a7497eff071e66a3dc971e1d3240cf6a2451f1f9a9b6ea00202eb541fbe0e2f9754e1802370ed1b7cd9d35d6d9b57fc80833fd38a27b7eae4d55b54392aacd4276c945b31eb0fef44c1f3e66a20c16c7ed054a86fbd4183825758c5245bcb65b42be96d981f7b31532e8a5f492aeeef53f00df4208480f4da2879f7bdb18e9ecc6fb7d9637ab90392baf2b951e2af63950008d6fba02fea6eb00e3101eff9295447b785e0d1fe48aeff0fff7bd\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.207, 74.125.201.207, 74.125.202.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10659199 (10M) [application/zip]\n",
            "Saving to: ‘Gesture_Detection_Swift-YOLO_192/dataset.zip’\n",
            "\n",
            "Gesture_Detection_S 100%[===================>]  10.17M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-12-25 07:25:46 (238 MB/s) - ‘Gesture_Detection_Swift-YOLO_192/dataset.zip’ saved [10659199/10659199]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p Gesture_Detection_Swift-YOLO_192/dataset\n",
        "!wget -c https://universe.roboflow.com/ds/xaMM3ZTeWy?key=5bznPZyI0t -O Gesture_Detection_Swift-YOLO_192/dataset.zip\n",
        "!unzip -q Gesture_Detection_Swift-YOLO_192/dataset.zip -d Gesture_Detection_Swift-YOLO_192/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvN1SLB41FkR"
      },
      "source": [
        "## 🚀Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DSKNIWBs1FkS",
        "outputId": "6f10d71c-17a2-4a32-d18b-691873fc0496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input shape (from config 'yolov5_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "12/25 07:26:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "12/25 07:26:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1579945287\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1579945287\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/25 07:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='mmyolo.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20231225_072634'}\n",
            "2023-12-25 07:26:37.840075: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 07:26:37.840173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 07:26:37.942807: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 07:26:40.066824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/25 07:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/25 07:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::add encountered 10 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul encountered 18 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::meshgrid encountered 3 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::clone encountered 3 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sub encountered 3 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul_ encountered 6 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "bbox_head.head_module.data_preprocessor, bbox_head.loss_bbox, bbox_head.loss_cls, bbox_head.loss_obj, data_preprocessor\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 57 time(s)\n",
            "12/25 07:26:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::upsample_nearest2d encountered 2 time(s)\n",
            "\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "|\u001b[1m \u001b[0m\u001b[1mmodule                                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "| model                                        | 0.7M                 | 90.806M    | 0.776M       |\n",
            "|  backbone                                    |  0.415M              |  65.958M   |  0.585M      |\n",
            "|   backbone.stem                              |   1.76K              |   16.22M   |   0.147M     |\n",
            "|    backbone.stem.conv                        |    1.728K            |    15.925M |    0.147M    |\n",
            "|    backbone.stem.bn                          |    32                |    0.295M  |    0         |\n",
            "|   backbone.stage1                            |   6.24K              |   14.377M  |   0.221M     |\n",
            "|    backbone.stage1.0                         |    3.504K            |    8.073M  |    55.296K   |\n",
            "|    backbone.stage1.1                         |    2.736K            |    6.304M  |    0.166M    |\n",
            "|   backbone.stage2                            |   20.24K             |   11.658M  |   0.115M     |\n",
            "|    backbone.stage2.0                         |    8.72K             |    5.023M  |    23.04K    |\n",
            "|    backbone.stage2.1                         |    11.52K            |    6.636M  |    92.16K    |\n",
            "|   backbone.stage3                            |   90.56K             |   13.041M  |   69.12K     |\n",
            "|    backbone.stage3.0                         |    28.96K            |    4.17M   |    11.52K    |\n",
            "|    backbone.stage3.1                         |    61.6K             |    8.87M   |    57.6K     |\n",
            "|   backbone.stage4                            |   0.296M             |   10.662M  |   31.68K     |\n",
            "|    backbone.stage4.0                         |    0.116M            |    4.159M  |    5.76K     |\n",
            "|    backbone.stage4.1                         |    0.116M            |    4.182M  |    17.28K    |\n",
            "|    backbone.stage4.2                         |    64.48K            |    2.321M  |    8.64K     |\n",
            "|  neck                                        |  0.279M              |  23.881M   |  0.173M      |\n",
            "|   neck.reduce_layers.2                       |   12.96K             |   0.467M   |   2.88K      |\n",
            "|    neck.reduce_layers.2.conv                 |    12.8K             |    0.461M  |    2.88K     |\n",
            "|    neck.reduce_layers.2.bn                   |    0.16K             |    5.76K   |    0         |\n",
            "|   neck.top_down_layers                       |   48K                |   10.817M  |   0.109M     |\n",
            "|    neck.top_down_layers.0                    |    38.96K            |    5.61M   |    40.32K    |\n",
            "|    neck.top_down_layers.1                    |    9.04K             |    5.207M  |    69.12K    |\n",
            "|   neck.downsample_layers                     |   72.24K             |   4.164M   |   8.64K      |\n",
            "|    neck.downsample_layers.0                  |    14.48K            |    2.085M  |    5.76K     |\n",
            "|    neck.downsample_layers.1                  |    57.76K            |    2.079M  |    2.88K     |\n",
            "|   neck.bottom_up_layers                      |   0.145M             |   8.398M   |   51.84K     |\n",
            "|    neck.bottom_up_layers.0                   |    29.28K            |    4.216M  |    34.56K    |\n",
            "|    neck.bottom_up_layers.1                   |    0.116M            |    4.182M  |    17.28K    |\n",
            "|   neck.upsample_layers                       |                      |   34.56K   |   0          |\n",
            "|    neck.upsample_layers.0                    |                      |    11.52K  |    0         |\n",
            "|    neck.upsample_layers.1                    |                      |    23.04K  |    0         |\n",
            "|  bbox_head.head_module.convs_pred            |  6.792K              |  0.968M    |  18.144K     |\n",
            "|   bbox_head.head_module.convs_pred.0         |   0.984K             |   0.553M   |   13.824K    |\n",
            "|    bbox_head.head_module.convs_pred.0.weight |    (24, 40, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module.convs_pred.0.bias   |    (24,)             |            |              |\n",
            "|   bbox_head.head_module.convs_pred.1         |   1.944K             |   0.276M   |   3.456K     |\n",
            "|    bbox_head.head_module.convs_pred.1.weight |    (24, 80, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module.convs_pred.1.bias   |    (24,)             |            |              |\n",
            "|   bbox_head.head_module.convs_pred.2         |   3.864K             |   0.138M   |   0.864K     |\n",
            "|    bbox_head.head_module.convs_pred.2.weight |    (24, 160, 1, 1)   |            |              |\n",
            "|    bbox_head.head_module.convs_pred.2.bias   |    (24,)             |            |              |\n",
            "+----------------------------------------------+----------------------+------------+--------------+\n",
            "\n",
            "========================================\n",
            "    Input Shape     :  [1, 3, 192, 192]  \n",
            "    Model Flops     :      90.806M       \n",
            "  Model Parameters  :        0.7M        \n",
            "========================================\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "12/25 07:26:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 60 .bias, 60 conv.weight, 57 other\n",
            "Loads checkpoint by local backend from path: Gesture_Detection_Swift-YOLO_192/pretrain.pth\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      1/10     8.2103     5.07     2.2647    0.8756   0:02:59  : 100%|███████████| 92/92 [00:17<00:00,  5.23it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      2/10     8.4909    5.3726    2.2421    0.8762   0:02:26  : 100%|███████████| 92/92 [00:16<00:00,  5.73it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      3/10     8.5204    5.3864    2.262     0.8719   0:02:04  : 100%|███████████| 92/92 [00:16<00:00,  5.64it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      4/10     8.4562    5.2822    2.2923    0.8817   0:01:45  : 100%|███████████| 92/92 [00:16<00:00,  5.60it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      5/10     8.3925    5.2562    2.2648    0.8715   0:01:27  : 100%|███████████| 92/92 [00:16<00:00,  5.47it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time      eta    \n",
            "   val       5/10     0.0853    0.2475   0:00:00  : 100%|███████████████████████████████| 11/11 [00:00<00:00, 12.35it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.22s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.867\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.415\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      6/10     8.5763    5.3579    2.3399    0.8785   0:01:09  : 100%|███████████| 92/92 [00:16<00:00,  5.67it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      7/10     8.7264    5.5762    2.2698    0.8804   0:00:51  : 100%|███████████| 92/92 [00:16<00:00,  5.72it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      8/10     8.503     5.3228    2.3029    0.8773   0:00:34  : 100%|███████████| 92/92 [00:16<00:00,  5.44it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      9/10     8.7145    5.5609    2.2728    0.8808   0:00:17  : 100%|███████████| 92/92 [00:16<00:00,  5.65it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     10/10     8.2897    5.1099    2.3194    0.8603   0:00:00  : 100%|███████████| 92/92 [00:15<00:00,  5.81it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      10/10     0.0282    0.1384    0.462     0.867     0.415      -1.0     0.463     0.487    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.472\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n"
          ]
        }
      ],
      "source": [
        "!sscma.train configs/yolov5/yolov5_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsENgldb1FkS"
      },
      "source": [
        "## 📦Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2c8fmTFm1FkT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('Gesture_Detection_Swift-YOLO_192/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WwIRYGH11FkT",
        "outputId": "c2db6337-a336-4b1e-f301-f151ac097de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using automatically generated input shape (from config 'yolov5_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "12/25 07:30:45 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "12/25 07:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1902817946\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1902817946\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/25 07:30:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='mmyolo.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20231225_073045'}\n",
            "2023-12-25 07:30:48.249263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 07:30:48.249310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 07:30:48.250681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 07:30:49.381614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/25 07:30:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/25 07:30:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "100%|███████████| 100/100 [00:07<00:00, 12.63it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:1209: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n",
            "/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/yolodetector_q.py:749: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_0_f = torch.as_tensor(8, dtype=torch.float32, device=device_1_f)\n",
            "/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/yolodetector_q.py:820: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_1_f = torch.as_tensor(16, dtype=torch.float32, device=device_3_f)\n",
            "/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/yolodetector_q.py:891: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_2_f = torch.as_tensor(32, dtype=torch.float32, device=device_5_f)\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1112 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1121 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1158 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1166 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1202 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1210 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.tflite\n",
            "TFLite: Successfully export model: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.tflite\n",
            "/content/ModelAssistant/sscma/models/heads/yolov5_head.py:113: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  xy = (feat_xy * 2 - 0.5 + grid) * torch.as_tensor(\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.tflite\n",
            "TFLite: Successfully export model: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.tflite\n",
            "ONNX: Ignoring unsupported precision: int8\n",
            "Exported graph: graph(%input : Float(1, 3, 192, 192, strides=[110592, 36864, 192, 1], requires_grad=0, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.weight : Float(24, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.weight : Float(24, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.weight : Float(24, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
            "      %onnx::Conv_836 : Float(16, 3, 6, 6, strides=[108, 36, 6, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_837 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_839 : Float(24, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_840 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_842 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_843 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_845 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_846 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_848 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_849 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_851 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_852 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_854 : Float(24, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_855 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_857 : Float(40, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_858 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_860 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_861 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_863 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_864 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_866 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_867 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_869 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_870 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_872 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_873 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_875 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_876 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_878 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_879 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_881 : Float(80, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_882 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_884 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_885 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_887 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_888 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_890 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_891 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_893 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_894 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_896 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_897 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_899 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_900 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_902 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_903 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_905 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_906 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_908 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_909 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_911 : Float(160, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_912 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_914 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_915 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_917 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_918 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_920 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_921 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_923 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_924 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_926 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_927 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_929 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_930 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_932 : Float(160, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_933 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_935 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_936 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_938 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_939 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_941 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_942 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_944 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_945 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_947 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_948 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_950 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_951 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_953 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_954 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_956 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_957 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_959 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_960 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_962 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_963 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_965 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_966 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_968 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_969 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_971 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_972 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_974 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_975 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_977 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_978 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_980 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_981 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_983 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_984 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_986 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_987 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_989 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_990 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_992 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_993 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_995 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_996 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_998 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_999 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1001 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1002 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1004 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1005 : Float(160, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %/backbone/stem/conv/Conv_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[6, 6], pads=[2, 2, 2, 2], strides=[2, 2], onnx_name=\"/backbone/stem/conv/Conv\"](%input, %onnx::Conv_836, %onnx::Conv_837), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/mmcv.cnn.bricks.conv_module.ConvModule::stem/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stem/activate/Relu_output_0 : Float(1, 16, 96, 96, strides=[147456, 9216, 96, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stem/activate/Relu\"](%/backbone/stem/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/mmcv.cnn.bricks.conv_module.ConvModule::stem/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage1/stage1.0/conv/Conv_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage1/stage1.0/conv/Conv\"](%/backbone/stem/activate/Relu_output_0, %onnx::Conv_839, %onnx::Conv_840), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmcv.cnn.bricks.conv_module.ConvModule::stage1.0/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.0/activate/Relu_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.0/activate/Relu\"](%/backbone/stage1/stage1.0/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmcv.cnn.bricks.conv_module.ConvModule::stage1.0/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/short_conv/conv/Conv\"](%/backbone/stage1/stage1.0/activate/Relu_output_0, %onnx::Conv_842, %onnx::Conv_843), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/activate/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/short_conv/activate/Relu\"](%/backbone/stage1/stage1.1/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/main_conv/conv/Conv\"](%/backbone/stage1/stage1.0/activate/Relu_output_0, %onnx::Conv_845, %onnx::Conv_846), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/activate/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/main_conv/activate/Relu\"](%/backbone/stage1/stage1.1/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/main_conv/activate/Relu_output_0, %onnx::Conv_848, %onnx::Conv_849), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/activate/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_851, %onnx::Conv_852), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/activate/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0 : Float(1, 12, 48, 48, strides=[27648, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/activate/Relu_output_0, %/backbone/stage1/stage1.1/main_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage1/stage1.1/Concat_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage1/stage1.1/Concat\"](%/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0, %/backbone/stage1/stage1.1/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/conv/Conv_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/final_conv/conv/Conv\"](%/backbone/stage1/stage1.1/Concat_output_0, %onnx::Conv_854, %onnx::Conv_855), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/activate/Relu_output_0 : Float(1, 24, 48, 48, strides=[55296, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/final_conv/activate/Relu\"](%/backbone/stage1/stage1.1/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/mmdet.models.layers.csp_layer.CSPLayer::stage1.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.0/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage2/stage2.0/conv/Conv\"](%/backbone/stage1/stage1.1/final_conv/activate/Relu_output_0, %onnx::Conv_857, %onnx::Conv_858), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmcv.cnn.bricks.conv_module.ConvModule::stage2.0/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.0/activate/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.0/activate/Relu\"](%/backbone/stage2/stage2.0/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmcv.cnn.bricks.conv_module.ConvModule::stage2.0/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/short_conv/conv/Conv\"](%/backbone/stage2/stage2.0/activate/Relu_output_0, %onnx::Conv_860, %onnx::Conv_861), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/short_conv/activate/Relu\"](%/backbone/stage2/stage2.1/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/main_conv/conv/Conv\"](%/backbone/stage2/stage2.0/activate/Relu_output_0, %onnx::Conv_863, %onnx::Conv_864), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/main_conv/activate/Relu\"](%/backbone/stage2/stage2.1/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/main_conv/activate/Relu_output_0, %onnx::Conv_866, %onnx::Conv_867), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/activate/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_869, %onnx::Conv_870), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/activate/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/activate/Relu_output_0, %/backbone/stage2/stage2.1/main_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0, %onnx::Conv_872, %onnx::Conv_873), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/activate/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/activate/Relu_output_0, %onnx::Conv_875, %onnx::Conv_876), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/activate/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/activate/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage2/stage2.1/Concat_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage2/stage2.1/Concat\"](%/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0, %/backbone/stage2/stage2.1/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/final_conv/conv/Conv\"](%/backbone/stage2/stage2.1/Concat_output_0, %onnx::Conv_878, %onnx::Conv_879), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/activate/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/final_conv/activate/Relu\"](%/backbone/stage2/stage2.1/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/mmdet.models.layers.csp_layer.CSPLayer::stage2.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.0/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage3/stage3.0/conv/Conv\"](%/backbone/stage2/stage2.1/final_conv/activate/Relu_output_0, %onnx::Conv_881, %onnx::Conv_882), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmcv.cnn.bricks.conv_module.ConvModule::stage3.0/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.0/activate/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.0/activate/Relu\"](%/backbone/stage3/stage3.0/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmcv.cnn.bricks.conv_module.ConvModule::stage3.0/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/short_conv/conv/Conv\"](%/backbone/stage3/stage3.0/activate/Relu_output_0, %onnx::Conv_884, %onnx::Conv_885), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/short_conv/activate/Relu\"](%/backbone/stage3/stage3.1/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/main_conv/conv/Conv\"](%/backbone/stage3/stage3.0/activate/Relu_output_0, %onnx::Conv_887, %onnx::Conv_888), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/main_conv/activate/Relu\"](%/backbone/stage3/stage3.1/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/main_conv/activate/Relu_output_0, %onnx::Conv_890, %onnx::Conv_891), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/activate/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_893, %onnx::Conv_894), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/activate/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/activate/Relu_output_0, %/backbone/stage3/stage3.1/main_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0, %onnx::Conv_896, %onnx::Conv_897), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/activate/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/activate/Relu_output_0, %onnx::Conv_899, %onnx::Conv_900), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/activate/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/activate/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0, %onnx::Conv_902, %onnx::Conv_903), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.2/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/activate/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.2/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/activate/Relu_output_0, %onnx::Conv_905, %onnx::Conv_906), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.2/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/activate/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.2/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/activate/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage3/stage3.1/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage3/stage3.1/Concat\"](%/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0, %/backbone/stage3/stage3.1/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/final_conv/conv/Conv\"](%/backbone/stage3/stage3.1/Concat_output_0, %onnx::Conv_908, %onnx::Conv_909), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/activate/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/final_conv/activate/Relu\"](%/backbone/stage3/stage3.1/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/mmdet.models.layers.csp_layer.CSPLayer::stage3.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.0/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage4/stage4.0/conv/Conv\"](%/backbone/stage3/stage3.1/final_conv/activate/Relu_output_0, %onnx::Conv_911, %onnx::Conv_912), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmcv.cnn.bricks.conv_module.ConvModule::stage4.0/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.0/activate/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.0/activate/Relu\"](%/backbone/stage4/stage4.0/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmcv.cnn.bricks.conv_module.ConvModule::stage4.0/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/short_conv/conv/Conv\"](%/backbone/stage4/stage4.0/activate/Relu_output_0, %onnx::Conv_914, %onnx::Conv_915), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/short_conv/activate/Relu\"](%/backbone/stage4/stage4.1/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/main_conv/conv/Conv\"](%/backbone/stage4/stage4.0/activate/Relu_output_0, %onnx::Conv_917, %onnx::Conv_918), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/main_conv/activate/Relu\"](%/backbone/stage4/stage4.1/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/main_conv/activate/Relu_output_0, %onnx::Conv_920, %onnx::Conv_921), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/activate/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_923, %onnx::Conv_924), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/activate/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/activate/Relu_output_0, %/backbone/stage4/stage4.1/main_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:77:0\n",
            "  %/backbone/stage4/stage4.1/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.1/Concat\"](%/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0, %/backbone/stage4/stage4.1/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/final_conv/conv/Conv\"](%/backbone/stage4/stage4.1/Concat_output_0, %onnx::Conv_926, %onnx::Conv_927), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/activate/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/final_conv/activate/Relu\"](%/backbone/stage4/stage4.1/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmdet.models.layers.csp_layer.CSPLayer::stage4.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/final_conv/activate/Relu_output_0, %onnx::Conv_929, %onnx::Conv_930), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv1/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv1/activate/Relu\"](%/backbone/stage4/stage4.2/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/backbone/stage4/stage4.2/poolings/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings/MaxPool\"](%/backbone/stage4/stage4.2/conv1/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_1/MaxPool\"](%/backbone/stage4/stage4.2/poolings/MaxPool_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_2/MaxPool\"](%/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/Concat_output_0 : Float(1, 320, 6, 6, strides=[11520, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.2/Concat\"](%/backbone/stage4/stage4.2/conv1/activate/Relu_output_0, %/backbone/stage4/stage4.2/poolings/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2 # /usr/local/lib/python3.10/dist-packages/mmyolo/models/layers/yolo_bricks.py:116:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/Conv\"](%/backbone/stage4/stage4.2/Concat_output_0, %onnx::Conv_932, %onnx::Conv_933), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv2/activate/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv2/activate/Relu\"](%/backbone/stage4/stage4.2/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/mmyolo.models.layers.yolo_bricks.SPPFBottleneck::stage4.2/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/reduce_layers.2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/reduce_layers.2/conv/Conv\"](%/backbone/stage4/stage4.2/conv2/activate/Relu_output_0, %onnx::Conv_935, %onnx::Conv_936), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmcv.cnn.bricks.conv_module.ConvModule::reduce_layers.2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/reduce_layers.2/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/reduce_layers.2/activate/Relu\"](%/neck/reduce_layers.2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmcv.cnn.bricks.conv_module.ConvModule::reduce_layers.2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/upsample_layers.0/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.0/Constant\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.0/Constant_1\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Resize_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.0/Resize\"](%/neck/reduce_layers.2/activate/Relu_output_0, %/neck/upsample_layers.0/Constant_1_output_0, %/neck/upsample_layers.0/Constant_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_output_0 : Float(1, 160, 12, 12, strides=[23040, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat\"](%/neck/upsample_layers.0/Resize_output_0, %/backbone/stage3/stage3.1/final_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck # /usr/local/lib/python3.10/dist-packages/mmyolo/models/necks/base_yolo_neck.py:242:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_938, %onnx::Conv_939), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/activate/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_941, %onnx::Conv_942), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/activate/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/activate/Relu_output_0, %onnx::Conv_944, %onnx::Conv_945), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/activate/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_947, %onnx::Conv_948), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/activate/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/Concat\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/activate/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0, %onnx::Conv_950, %onnx::Conv_951), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/activate/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/activate/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/activate/Relu_output_0, %onnx::Conv_953, %onnx::Conv_954), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::top_down_layers.0.1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/activate/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::top_down_layers.0.1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/upsample_layers.1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.1/Constant\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.1/Constant_1\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Resize_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.1/Resize\"](%/neck/top_down_layers.0/top_down_layers.0.1/activate/Relu_output_0, %/neck/upsample_layers.1/Constant_1_output_0, %/neck/upsample_layers.1/Constant_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_1_output_0 : Float(1, 80, 24, 24, strides=[46080, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_1\"](%/neck/upsample_layers.1/Resize_output_0, %/backbone/stage2/stage2.1/final_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck # /usr/local/lib/python3.10/dist-packages/mmyolo/models/necks/base_yolo_neck.py:242:0\n",
            "  %/neck/top_down_layers.1/short_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/short_conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_956, %onnx::Conv_957), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/short_conv/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/short_conv/activate/Relu\"](%/neck/top_down_layers.1/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.1/main_conv/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/main_conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_959, %onnx::Conv_960), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/main_conv/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/main_conv/activate/Relu\"](%/neck/top_down_layers.1/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv\"](%/neck/top_down_layers.1/main_conv/activate/Relu_output_0, %onnx::Conv_962, %onnx::Conv_963), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/activate/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_965, %onnx::Conv_966), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 20, 24, 24, strides=[11520, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/activate/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/top_down_layers.1/Concat_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.1/Concat\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/activate/Relu_output_0, %/neck/top_down_layers.1/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/neck/top_down_layers.1/final_conv/conv/Conv_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/final_conv/conv/Conv\"](%/neck/top_down_layers.1/Concat_output_0, %onnx::Conv_968, %onnx::Conv_969), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/final_conv/activate/Relu_output_0 : Float(1, 40, 24, 24, strides=[23040, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/final_conv/activate/Relu\"](%/neck/top_down_layers.1/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::top_down_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/downsample_layers.0/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.0/conv/Conv\"](%/neck/top_down_layers.1/final_conv/activate/Relu_output_0, %onnx::Conv_971, %onnx::Conv_972), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmcv.cnn.bricks.conv_module.ConvModule::downsample_layers.0/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.0/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.0/activate/Relu\"](%/neck/downsample_layers.0/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmcv.cnn.bricks.conv_module.ConvModule::downsample_layers.0/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/Concat_2_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_2\"](%/neck/downsample_layers.0/activate/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.1/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck # /usr/local/lib/python3.10/dist-packages/mmyolo/models/necks/base_yolo_neck.py:256:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/short_conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_974, %onnx::Conv_975), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/short_conv/activate/Relu\"](%/neck/bottom_up_layers.0/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/main_conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_977, %onnx::Conv_978), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/main_conv/activate/Relu\"](%/neck/bottom_up_layers.0/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv\"](%/neck/bottom_up_layers.0/main_conv/activate/Relu_output_0, %onnx::Conv_980, %onnx::Conv_981), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/activate/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_983, %onnx::Conv_984), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/activate/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.0/Concat_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.0/Concat\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/activate/Relu_output_0, %/neck/bottom_up_layers.0/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/conv/Conv_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/final_conv/conv/Conv\"](%/neck/bottom_up_layers.0/Concat_output_0, %onnx::Conv_986, %onnx::Conv_987), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/activate/Relu_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/final_conv/activate/Relu\"](%/neck/bottom_up_layers.0/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/downsample_layers.1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.1/conv/Conv\"](%/neck/bottom_up_layers.0/final_conv/activate/Relu_output_0, %onnx::Conv_989, %onnx::Conv_990), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmcv.cnn.bricks.conv_module.ConvModule::downsample_layers.1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.1/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.1/activate/Relu\"](%/neck/downsample_layers.1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmcv.cnn.bricks.conv_module.ConvModule::downsample_layers.1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/Concat_3_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_3\"](%/neck/downsample_layers.1/activate/Relu_output_0, %/neck/reduce_layers.2/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck # /usr/local/lib/python3.10/dist-packages/mmyolo/models/necks/base_yolo_neck.py:256:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/short_conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_992, %onnx::Conv_993), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/short_conv/activate/Relu\"](%/neck/bottom_up_layers.1/short_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::short_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/main_conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_995, %onnx::Conv_996), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/main_conv/activate/Relu\"](%/neck/bottom_up_layers.1/main_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::main_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv\"](%/neck/bottom_up_layers.1/main_conv/activate/Relu_output_0, %onnx::Conv_998, %onnx::Conv_999), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/activate/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv1/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/activate/Relu_output_0, %onnx::Conv_1001, %onnx::Conv_1002), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/activate/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/activate/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/mmdet.models.layers.csp_layer.DarknetBottleneck::blocks.0/mmcv.cnn.bricks.conv_module.ConvModule::conv2/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/neck/bottom_up_layers.1/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.1/Concat\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/activate/Relu_output_0, %/neck/bottom_up_layers.1/short_conv/activate/Relu_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1 # /usr/local/lib/python3.10/dist-packages/mmdet/models/layers/csp_layer.py:242:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/conv/Conv_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/final_conv/conv/Conv\"](%/neck/bottom_up_layers.1/Concat_output_0, %onnx::Conv_1004, %onnx::Conv_1005), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/activate/Relu_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/final_conv/activate/Relu\"](%/neck/bottom_up_layers.1/final_conv/conv/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/mmyolo.models.necks.yolov5_pafpn.YOLOv5PAFPN::neck/mmdet.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/mmcv.cnn.bricks.conv_module.ConvModule::final_conv/torch.nn.modules.activation.ReLU::activate # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1455:0\n",
            "  %/convs_pred.0/Conv_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.0/Conv\"](%/neck/top_down_layers.1/final_conv/activate/Relu_output_0, %bbox_head.head_module.convs_pred.0.weight, %bbox_head.head_module.convs_pred.0.bias), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid\"](%/convs_pred.0/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:100:0\n",
            "  %/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    8  576 [ CPULongType{4} ], onnx_name=\"/Constant\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:102:0\n",
            "  %/Reshape_output_0 : Float(1, 3, 8, 576, strides=[13824, 4608, 576, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape\"](%/Sigmoid_output_0, %/Constant_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:102:0\n",
            "  %/Transpose_output_0 : Float(1, 3, 576, 8, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose\"](%/Reshape_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:103:0\n",
            "  %/convs_pred.1/Conv_output_0 : Float(1, 24, 12, 12, strides=[3456, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.1/Conv\"](%/neck/bottom_up_layers.0/final_conv/activate/Relu_output_0, %bbox_head.head_module.convs_pred.1.weight, %bbox_head.head_module.convs_pred.1.bias), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_1_output_0 : Float(1, 24, 12, 12, strides=[3456, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_1\"](%/convs_pred.1/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:100:0\n",
            "  %/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    8  144 [ CPULongType{4} ], onnx_name=\"/Constant_1\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:102:0\n",
            "  %/Reshape_1_output_0 : Float(1, 3, 8, 144, strides=[3456, 1152, 144, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_1\"](%/Sigmoid_1_output_0, %/Constant_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:102:0\n",
            "  %/Transpose_1_output_0 : Float(1, 3, 144, 8, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_1\"](%/Reshape_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:103:0\n",
            "  %/convs_pred.2/Conv_output_0 : Float(1, 24, 6, 6, strides=[864, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.2/Conv\"](%/neck/bottom_up_layers.1/final_conv/activate/Relu_output_0, %bbox_head.head_module.convs_pred.2.weight, %bbox_head.head_module.convs_pred.2.bias), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_2_output_0 : Float(1, 24, 6, 6, strides=[864, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_2\"](%/convs_pred.2/Conv_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:100:0\n",
            "  %/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3   8  36 [ CPULongType{4} ], onnx_name=\"/Constant_2\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:102:0\n",
            "  %/Reshape_2_output_0 : Float(1, 3, 8, 36, strides=[864, 288, 36, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_2\"](%/Sigmoid_2_output_0, %/Constant_2_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:102:0\n",
            "  %/Transpose_2_output_0 : Float(1, 3, 36, 8, strides=[864, 288, 8, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_2\"](%/Reshape_2_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:103:0\n",
            "  %/Constant_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 24  24 [ CPULongType{2} ], onnx_name=\"/Constant_3\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_4_output_0 : Long(24, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_4\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_output_0 : Long(24, 24, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand\"](%/Constant_4_output_0, %/Constant_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::\n",
            "  %/Constant_5_output_0 : Long(1, 24, strides=[24, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_5\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_1_output_0 : Long(24, 24, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_1\"](%/Constant_5_output_0, %/Constant_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::\n",
            "  %/Unsqueeze_output_0 : Long(24, 24, 1, strides=[24, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze\"](%/Expand_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Unsqueeze_1_output_0 : Long(24, 24, 1, strides=[24, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_1\"](%/Expand_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_output_0 : Long(24, 24, 2, strides=[48, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat\"](%/Unsqueeze_output_0, %/Unsqueeze_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_6_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  24  24   2 [ CPULongType{5} ], onnx_name=\"/Constant_6\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_7\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/ConstantOfShape_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape\"](%/Constant_7_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_8\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/ConstantOfShape_output_0, %/Constant_8_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Equal_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal\"](%/Constant_6_output_0, %/Mul_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Where_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where\"](%/Equal_output_0, %/ConstantOfShape_output_0, %/Constant_6_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Expand_2_output_0 : Long(1, 1, 24, 24, 2, strides=[1152, 1152, 48, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_2\"](%/Concat_output_0, %/Where_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_9\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Reshape_3_output_0 : Long(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_3\"](%/Expand_2_output_0, %/Constant_9_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Cast_output_0 : Float(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast\"](%/Reshape_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Cast_1_output_0 : Float(1, 1, 576, 2, strides=[1152, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_1\"](%/Cast_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %onnx::Expand_636 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    10  13  (1,2,.,.) =    16  30  (1,3,.,.) =    33  23 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_10_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  576    2 [ CPULongType{4} ], onnx_name=\"/Constant_10\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_11\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/ConstantOfShape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_1\"](%/Constant_11_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_12\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/ConstantOfShape_1_output_0, %/Constant_12_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_1\"](%/Constant_10_output_0, %/Mul_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_1\"](%/Equal_1_output_0, %/ConstantOfShape_1_output_0, %/Constant_10_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Expand_3_output_0 : Long(1, 3, 576, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_3\"](%onnx::Expand_636, %/Where_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Cast_2_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_2\"](%/Expand_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:137:0\n",
            "  %/Cast_3_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_3\"](%/Cast_2_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:138:0\n",
            "  %/Split_output_0 : Float(1, 3, 576, 2, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu), %/Split_output_1 : Float(1, 3, 576, 2, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu), %/Split_output_2 : Float(1, 3, 576, 4, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 4], onnx_name=\"/Split\"](%/Transpose_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_13\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Mul_2_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_2\"](%/Split_output_0, %/Constant_13_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_14\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Sub_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub\"](%/Mul_2_output_0, %/Constant_14_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Add_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Sub_output_0, %/Cast_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/Constant_15\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Mul_3_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_3\"](%/Add_output_0, %/Constant_15_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_16\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:116:0\n",
            "  %/Mul_4_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_4\"](%/Split_output_1, %/Constant_16_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:116:0\n",
            "  %/Mul_5_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_5\"](%/Mul_4_output_0, %/Mul_4_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:117:0\n",
            "  %/Mul_6_output_0 : Float(1, 3, 576, 2, strides=[3456, 1152, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_6\"](%/Mul_5_output_0, %/Cast_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:118:0\n",
            "  %/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_17\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:119:0\n",
            "  %/Mul_7_output_0 : Float(1, 3, 576, 4, strides=[6912, 2304, 4, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_7\"](%/Split_output_2, %/Constant_17_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:119:0\n",
            "  %/Concat_1_output_0 : Float(1, 3, 576, 8, strides=[13824, 4608, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_1\"](%/Mul_3_output_0, %/Mul_6_output_0, %/Mul_7_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:120:0\n",
            "  %/Constant_18_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  8 [ CPULongType{3} ], onnx_name=\"/Constant_18\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:121:0\n",
            "  %/Reshape_4_output_0 : Float(1, 1728, 8, strides=[13824, 8, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_4\"](%/Concat_1_output_0, %/Constant_18_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:121:0\n",
            "  %/Constant_19_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 12  12 [ CPULongType{2} ], onnx_name=\"/Constant_19\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_20_output_0 : Long(12, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_20\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_4_output_0 : Long(12, 12, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_4\"](%/Constant_20_output_0, %/Constant_19_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::\n",
            "  %/Constant_21_output_0 : Long(1, 12, strides=[12, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_21\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_5_output_0 : Long(12, 12, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_5\"](%/Constant_21_output_0, %/Constant_19_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::\n",
            "  %/Unsqueeze_2_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_2\"](%/Expand_5_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Unsqueeze_3_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_3\"](%/Expand_4_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_2_output_0 : Long(12, 12, 2, strides=[24, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_2\"](%/Unsqueeze_2_output_0, %/Unsqueeze_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_22_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  12  12   2 [ CPULongType{5} ], onnx_name=\"/Constant_22\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_23\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/ConstantOfShape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_2\"](%/Constant_23_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_24\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_8_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_8\"](%/ConstantOfShape_2_output_0, %/Constant_24_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Equal_2_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_2\"](%/Constant_22_output_0, %/Mul_8_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Where_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_2\"](%/Equal_2_output_0, %/ConstantOfShape_2_output_0, %/Constant_22_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Expand_6_output_0 : Long(1, 1, 12, 12, 2, strides=[288, 288, 24, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_6\"](%/Concat_2_output_0, %/Where_2_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_25_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_25\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Reshape_5_output_0 : Long(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_5\"](%/Expand_6_output_0, %/Constant_25_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Cast_4_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_4\"](%/Reshape_5_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Cast_5_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_5\"](%/Cast_4_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %onnx::Expand_716 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    30  61  (1,2,.,.) =    62  45  (1,3,.,.) =     59  119 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_26_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  144    2 [ CPULongType{4} ], onnx_name=\"/Constant_26\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_27\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_3\"](%/Constant_27_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Constant_28_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_28\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Mul_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_9\"](%/ConstantOfShape_3_output_0, %/Constant_28_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_3\"](%/Constant_26_output_0, %/Mul_9_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_3\"](%/Equal_3_output_0, %/ConstantOfShape_3_output_0, %/Constant_26_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Expand_7_output_0 : Long(1, 3, 144, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_7\"](%onnx::Expand_716, %/Where_3_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Cast_6_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_6\"](%/Expand_7_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:137:0\n",
            "  %/Cast_7_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_7\"](%/Cast_6_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:138:0\n",
            "  %/Split_1_output_0 : Float(1, 3, 144, 2, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu), %/Split_1_output_1 : Float(1, 3, 144, 2, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu), %/Split_1_output_2 : Float(1, 3, 144, 4, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 4], onnx_name=\"/Split_1\"](%/Transpose_1_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_29_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_29\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Mul_10_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_10\"](%/Split_1_output_0, %/Constant_29_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_30_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_30\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Sub_1_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_1\"](%/Mul_10_output_0, %/Constant_30_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Add_1_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/Sub_1_output_0, %/Cast_5_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_31_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/Constant_31\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Mul_11_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_11\"](%/Add_1_output_0, %/Constant_31_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_32_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_32\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:116:0\n",
            "  %/Mul_12_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_12\"](%/Split_1_output_1, %/Constant_32_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:116:0\n",
            "  %/Mul_13_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_13\"](%/Mul_12_output_0, %/Mul_12_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:117:0\n",
            "  %/Mul_14_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_14\"](%/Mul_13_output_0, %/Cast_7_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:118:0\n",
            "  %/Constant_33_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_33\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:119:0\n",
            "  %/Mul_15_output_0 : Float(1, 3, 144, 4, strides=[1728, 576, 4, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_15\"](%/Split_1_output_2, %/Constant_33_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:119:0\n",
            "  %/Concat_3_output_0 : Float(1, 3, 144, 8, strides=[3456, 1152, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_3\"](%/Mul_11_output_0, %/Mul_14_output_0, %/Mul_15_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:120:0\n",
            "  %/Constant_34_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  8 [ CPULongType{3} ], onnx_name=\"/Constant_34\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:121:0\n",
            "  %/Reshape_6_output_0 : Float(1, 432, 8, strides=[3456, 8, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_6\"](%/Concat_3_output_0, %/Constant_34_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:121:0\n",
            "  %/Constant_35_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 6  6 [ CPULongType{2} ], onnx_name=\"/Constant_35\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_36_output_0 : Long(6, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{6,1} ], onnx_name=\"/Constant_36\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_8_output_0 : Long(6, 6, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_8\"](%/Constant_36_output_0, %/Constant_35_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::\n",
            "  %/Constant_37_output_0 : Long(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{1,6} ], onnx_name=\"/Constant_37\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_9_output_0 : Long(6, 6, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_9\"](%/Constant_37_output_0, %/Constant_35_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector::\n",
            "  %/Unsqueeze_4_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_4\"](%/Expand_9_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Unsqueeze_5_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_5\"](%/Expand_8_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_4_output_0 : Long(6, 6, 2, strides=[12, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_4\"](%/Unsqueeze_4_output_0, %/Unsqueeze_5_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_38_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  6  6  2 [ CPULongType{5} ], onnx_name=\"/Constant_38\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_39\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/ConstantOfShape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_4\"](%/Constant_39_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_40_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_40\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_16_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_16\"](%/ConstantOfShape_4_output_0, %/Constant_40_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Equal_4_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_4\"](%/Constant_38_output_0, %/Mul_16_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Where_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_4\"](%/Equal_4_output_0, %/ConstantOfShape_4_output_0, %/Constant_38_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Expand_10_output_0 : Long(1, 1, 6, 6, 2, strides=[72, 72, 12, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_10\"](%/Concat_4_output_0, %/Where_4_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Constant_41_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_41\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Reshape_7_output_0 : Long(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_7\"](%/Expand_10_output_0, %/Constant_41_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Cast_8_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_8\"](%/Reshape_7_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Cast_9_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_9\"](%/Cast_8_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %onnx::Expand_795 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    116   90  (1,2,.,.) =    156  198  (1,3,.,.) =    373  326 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_42_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3  36   2 [ CPULongType{4} ], onnx_name=\"/Constant_42\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_43\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_5\"](%/Constant_43_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Constant_44_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_44\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Mul_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_17\"](%/ConstantOfShape_5_output_0, %/Constant_44_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_5\"](%/Constant_42_output_0, %/Mul_17_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_5\"](%/Equal_5_output_0, %/ConstantOfShape_5_output_0, %/Constant_42_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Expand_11_output_0 : Long(1, 3, 36, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_11\"](%onnx::Expand_795, %/Where_5_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:136:0\n",
            "  %/Cast_10_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_10\"](%/Expand_11_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:137:0\n",
            "  %/Cast_11_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_11\"](%/Cast_10_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:138:0\n",
            "  %/Split_2_output_0 : Float(1, 3, 36, 2, strides=[864, 288, 8, 1], requires_grad=0, device=cpu), %/Split_2_output_1 : Float(1, 3, 36, 2, strides=[864, 288, 8, 1], requires_grad=0, device=cpu), %/Split_2_output_2 : Float(1, 3, 36, 4, strides=[864, 288, 8, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 4], onnx_name=\"/Split_2\"](%/Transpose_2_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /usr/local/lib/python3.10/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_45_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_45\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Mul_18_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_18\"](%/Split_2_output_0, %/Constant_45_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_46_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_46\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Sub_2_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_2\"](%/Mul_18_output_0, %/Constant_46_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Add_2_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_2\"](%/Sub_2_output_0, %/Cast_9_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_47_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name=\"/Constant_47\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Mul_19_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_19\"](%/Add_2_output_0, %/Constant_47_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:113:0\n",
            "  %/Constant_48_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_48\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:116:0\n",
            "  %/Mul_20_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_20\"](%/Split_2_output_1, %/Constant_48_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:116:0\n",
            "  %/Mul_21_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_21\"](%/Mul_20_output_0, %/Mul_20_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:117:0\n",
            "  %/Mul_22_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_22\"](%/Mul_21_output_0, %/Cast_11_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:118:0\n",
            "  %/Constant_49_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_49\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:119:0\n",
            "  %/Mul_23_output_0 : Float(1, 3, 36, 4, strides=[432, 144, 4, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_23\"](%/Split_2_output_2, %/Constant_49_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:119:0\n",
            "  %/Concat_5_output_0 : Float(1, 3, 36, 8, strides=[864, 288, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_5\"](%/Mul_19_output_0, %/Mul_22_output_0, %/Mul_23_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:120:0\n",
            "  %/Constant_50_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  8 [ CPULongType{3} ], onnx_name=\"/Constant_50\"](), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:121:0\n",
            "  %/Reshape_8_output_0 : Float(1, 108, 8, strides=[864, 8, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_8\"](%/Concat_5_output_0, %/Constant_50_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:121:0\n",
            "  %output : Float(1, 2268, 8, strides=[18144, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_6\"](%/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0), scope: mmyolo.models.detectors.yolo_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:123:0\n",
            "  return (%output)\n",
            "\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "ONNX: Successfully export model: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.onnx\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/sscma.export\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/content/ModelAssistant/sscma/tools/export.py\", line 453, in main\n",
            "    export_pnnx(args, model)\n",
            "  File \"/content/ModelAssistant/sscma/tools/export.py\", line 264, in export_pnnx\n",
            "    from pnnx.wrapper import convert_inputshape_to_cmd\n",
            "ModuleNotFoundError: No module named 'pnnx.wrapper'\n"
          ]
        }
      ],
      "source": [
        "!sscma.export configs/yolov5/yolov5_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94yN6Tjt1FkT"
      },
      "source": [
        "### 📝Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzVeVofo1FkU"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tQPy6OBC1FkU",
        "outputId": "6c17c867-5e1a-454d-b3b7-c25ca7a7eca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10.pkl\n",
            "12/25 07:31:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "12/25 07:31:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1220348915\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1220348915\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/25 07:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='mmyolo.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20231225_073156'}\n",
            "2023-12-25 07:31:59.588509: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 07:31:59.588580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 07:31:59.590546: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 07:32:01.223691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/25 07:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/25 07:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.48s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.472\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaAFLYCh1FkU"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "84Yri1Xe1FkV",
        "outputId": "e46597d7-0c6b-44b1-a2f8-b019d3053e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.pkl\n",
            "12/25 07:33:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "12/25 07:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 311643288\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 311643288\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/25 07:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='mmyolo.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20231225_073303'}\n",
            "2023-12-25 07:33:05.983057: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 07:33:05.983108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 07:33:05.984633: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 07:33:07.117612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/25 07:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/25 07:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/166 [00:00<?, ?it/s]12/25 07:33:10 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/25 07:33:10 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 166/166 [00:02<00:00, 75.42it/s]\n",
            "12/25 07:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.921\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
            "12/25 07:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.448 0.921 0.383 -1.000 0.439 0.471\n",
            "{'coco/bbox_mAP': 0.448, 'coco/bbox_mAP_50': 0.921, 'coco/bbox_mAP_75': 0.383, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.439, 'coco/bbox_mAP_l': 0.471}\n",
            "FPS: 169.535988 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXfeo7hV1FkV"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yXM206ly1FkV",
        "outputId": "1b955241-e722-40f0-f4b7-848cf3e20019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.pkl\n",
            "12/25 07:33:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "12/25 07:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 272731880\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 272731880\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/25 07:33:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='mmyolo.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_float32.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20231225_073346'}\n",
            "2023-12-25 07:33:49.077951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 07:33:49.078020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 07:33:49.080077: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 07:33:50.592234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/25 07:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/25 07:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/166 [00:00<?, ?it/s]12/25 07:33:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/25 07:33:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 166/166 [00:01<00:00, 95.67it/s]\n",
            "12/25 07:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.921\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
            "12/25 07:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.448 0.921 0.383 -1.000 0.439 0.471\n",
            "{'coco/bbox_mAP': 0.448, 'coco/bbox_mAP_50': 0.921, 'coco/bbox_mAP_75': 0.383, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.439, 'coco/bbox_mAP_l': 0.471}\n",
            "FPS: 142.769358 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAmN9qF81FkV"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-vuHQXBO1FkW",
        "outputId": "55db4c74-2ee3-4a15-bc5b-f28859de67a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.pkl\n",
            "12/25 07:34:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
            "12/25 07:34:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 2020599642\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 2020599642\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/25 07:34:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=10,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'mmyolo'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 10\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=3,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.5,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=1.0,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='mmyolo.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 3\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/epoch_10_int8.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='LetterResize'),\n",
            "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='LetterResize'),\n",
            "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20231225_073429'}\n",
            "2023-12-25 07:34:32.462036: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-25 07:34:32.462091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-25 07:34:32.463415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-25 07:34:33.648116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/25 07:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/25 07:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/166 [00:00<?, ?it/s]12/25 07:34:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/25 07:34:37 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 166/166 [00:03<00:00, 53.52it/s]\n",
            "12/25 07:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.931\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n",
            "12/25 07:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.440 0.931 0.319 -1.000 0.428 0.454\n",
            "{'coco/bbox_mAP': 0.44, 'coco/bbox_mAP_50': 0.931, 'coco/bbox_mAP_75': 0.319, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.428, 'coco/bbox_mAP_l': 0.454}\n",
            "FPS: 98.881326 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-TI6V-X1FkW"
      },
      "source": [
        "## 🤖 Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CiFCR581FkW"
      },
      "outputs": [],
      "source": [
        "%ls -lh Gesture_Detection_Swift-YOLO_192/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S89KIk4D1FkW"
      },
      "source": [
        "### Thanks for Trying Out SSCMA 🎉\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star ✨ on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}